verbose=1
backgroundClassLabel=0

[train]

trainSetName=window_training


#training on merged set: geoautomation + bgWindowset

trainSet=/esat/kochab/mmathias/facedesData/doorEvaluationSet_halfSize/trainset.txt
testSet=

# x,y, width, height
objectWindow=10,17,52,106
modelWindow=72,140
offsetX=20
offsetY=20

outputModelFileName=trained_doors_generic.proto.bin
                    

# 500 weak classifiers
numIterations=500

bootStrapLearnerFile=

# 30000 candidate features
featuresPoolSize=80000

# level 2 decision trees
decisionTreeDepth=1

# DBP means: Direct Backward Prunning (see C. Zang and P. Viola 2007)
cascadeType=dbp

numNegativeSamples = 2000 

[bootstrapTrain]

# 2000 weak classifiers
#classifiersPerStage=20
#classifiersPerStage=200
#classifiersPerStage=200
#classifiersPerStage=700

#maxNumSamplesPerImage=0
#maxNumSamplesPerImage=5
#maxNumSamplesPerImage=5
#maxNumSamplesPerImage=5

classifiersPerStage=200
classifiersPerStage=400
classifiersPerStage=2000
classifiersPerStage=2000
classifiersPerStage=4000

maxNumSamplesPerImage=5
maxNumSamplesPerImage=5
maxNumSamplesPerImage=-1
maxNumSamplesPerImage=-1
maxNumSamplesPerImage=-1


# number of samples collected at each stage
# first stage takes random negative samples, then we take hard negative samples
numBootstrappingSamples=1300

min_scale = 0.8
max_scale = 2.8
num_scales =50 

min_ratio = 0.7
max_ratio = 1.3
num_ratios = 10

[test]
classifierName=model_for_test.proto.bin
#testSet=trainfull.txt
testSet=testfull.txt

# from testing example top-left corner to model window
offsetX=20
offsetY=20

