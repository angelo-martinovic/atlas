verbose=1
backgroundClassLabel=0

[train]
trainSetName=facesAFLW_octave_0.0 
trainSet=/esat/kochab/mmathias/faceData/aflw/trainset_sideview_new.txt
# testSet=/esat/kochab/mmathias/facedesData/windowHaussmannEvaluationSet/1/evalset.txt
testSet=
offsetX=10
offsetY=10
outputModelFileName=trained_faces_model_octave0.0.proto.bin
objectWindow=10,10,60,60
modelWindow=80,80


# 2000 weak classifiers
numIterations=2000 

bootStrapLearnerFile=

# 30000 candidate features
featuresPoolSize=50000
featurePoolType=HOG-multiScale


typeAdaboost=discrete

# level 2 decision trees
decisionTreeDepth=1

# FIXME what does dbp means ?
cascadeType=dbp

numNegativeSamples=2000

[bootstrapTrain]

# 2000 weak classifiers
#this is the setting used so far for the 3n models
#classifiersPerStage=200
#classifiersPerStage=1000
#classifiersPerStage=2000
#classifiersPerStage=2000

classifiersPerStage=2000
classifiersPerStage=2000
classifiersPerStage=2000
classifiersPerStage=10000

maxNumSamplesPerImage=3
maxNumSamplesPerImage=5
maxNumSamplesPerImage=-1
maxNumSamplesPerImage=-1


min_scale = 0.6
max_scale = 3
num_scales =30 

min_ratio = 1
max_ratio = 1 
num_ratios = 1

# number of samples collected at each stage
# first stage takes random negative samples, then we take hard negative samples
numBootstrappingSamples=3000
frugalMemoryUsage = 1

[test]
offsetX=10
offsetY=10
