verbose=1
backgroundClassLabel=0
task=bootstrapTrain

[train]

trainSetName=InriaPerson_octave_0.0
featurePoolType=HOG-multiScale

# At octave 0, object_to_model_border == 16, model (width, height) == (64, 128) and cropping_border == 20
#trainSet=/esat/vesta/rbenenson/data/2012_04_04_multiscales_inria_person/training_set_large_enough_negatives/positives_octave_0.0
#trainSet=/users/visics/rbenenso/data/multiscales_inria_person/training_set/positives_octave_0.0
#trainSet=/esat/vesta/rbenenson/data/2012_04_04_multiscales_inria_person/training_set/positives_octave_0.0
#testSet=/esat/vesta/rbenenson/data/2012_04_04_multiscales_inria_person/testing_set/positives_octave_0.0
#validationSet=/esat/kochab/mmathias/VOCdevkit/validationSet/validationset.txt

trainSet=/home/rodrigob/data/INRIAPerson_multiscales/train/positives_octave_0.0
testSet=/home/rodrigob/data/INRIAPerson_multiscales/test/positives_octave_0.0
validationSet=

outputModelFileName=all_squares_hog6_luv.proto.bin
#outputModelFileName=all_squares_hog6_luv.proto.bin

# x, y, width, height
objectWindow=8,16,48,96
modelWindow=64,128

# from training example top-left corner to model window
offsetX=20
offsetY=20

minFeatWidth=4
minFeatHeight=4

# number of weak classifiers
numIterations=2000 
#numIterations=5000 
#numIterations=10000 

bootStrapLearnerFile=

useStumpSets=false

# 30000 candidate features
featuresPoolSize=30000

# FIXME is this even used ?
#maxFeatureSizeRatio=0.9

# FIXME is this even used ?
typeAdaboost=discrete

# level 2 decision trees
decisionTreeDepth=1

# DBP means: Direct Backward Prunning (see C. Zang and P. Viola 2007)
cascadeType=dbp

numNegativeSamples = 5000
#numNegativeSamples = 15000

[bootstrapTrain]

# 2000 weak classifiers
classifiersPerStage=2000
classifiersPerStage=2000
classifiersPerStage=2000

#classifiersPerStage=100
#classifiersPerStage=100
#classifiersPerStage=100

#maxNumSamplesPerImage=0
#maxNumSamplesPerImage=-1
#maxNumSamplesPerImage=-1

maxNumSamplesPerImage=0
maxNumSamplesPerImage=5
maxNumSamplesPerImage=-1


# number of samples collected at each stage
# first stage takes random negative samples, then we take hard negative samples
numBootstrappingSamples=5000

# defaults for INRIAPerson detections
min_scale = 0.6094
max_scale = 8.6
num_scales = 55

min_ratio = 1
max_ratio = 1
num_ratios = 1

[test]

classifierName=/home/rodrigob/code/biclop_whitened_features/src/applications/boosted_learning/2013_03_26_37827_trained_model_octave_0.strong_baseline.proto.bin
#classifierName=/home/rodrigob/code/biclop_geodesic/src/applications/boosted_learning/models/whichWeakClassifier/Level2DecisionTree/2012_10_31_7330_HOG-multiscale.bootstrap2

#testSet=trainfull.txt
#testSet=testfull.txt
#testSet=test_positives_filepaths.txt
#testSet=train_positives_crisp.txt
testSet=train_positives_non_crisp.txt

# from testing example top-left corner to model window
offsetX=20
offsetY=20

